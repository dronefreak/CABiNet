# train_citys.yaml
# Hydra-based configuration for CABiNet training on Cityscapes

defaults: # these are the sub-config files for specific details, noee for the moment.
  - _self_ # this makes the top-level config take priority over sub-configs, see https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order/
  - model: mobilenetv3_large
  - dataset: cityscapes

# Training Configuration
training_config:
  batch_size: 8
  num_workers: 16
  epochs: 200
  optimizer_momentum: 0.9
  optimizer_weight_decay: 5e-4
  optimizer_lr_start: 5e-3
  optimizer_power: 0.9
  warmup_steps: 4000
  warmup_start_lr: 1e-5
  max_iterations: 200000
  class_balancing: true
  log_iter: 20 # Renamed from 'msg_iterations' â€” clearer intent
  experiments_path: experiments/cabinet_experiments_large_1024x1024
  model_save_name: cabinet_citys_large_1024x1024.pth

# Validation Configuration
validation_config:
  batch_size: 2
  num_workers: 8 # Explicitly set (can be lower than training)
  eval_scales: [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]
  flip: true
  results_path: ${training_config.experiments_path}/results # Consistent output location
  save_predictions: false # Optional: save .png preds during eval

# Runtime & Reproducibility
runtime:
  seed: 15 # For torch.manual_seed, numpy, random
  cudnn_benchmark: true # Faster convolutions (if input size stable)
  deterministic: false # Set to true for full reproducibility (slower)

# Hydra-specific settings
hydra:
  run:
    dir: ${training_config.experiments_path}/runs/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: ${training_config.experiments_path}/sweeps
    subdir: ${hydra.job.num}
